1) i have interest on data, i have more interest on problem solving and this interest was brought me to this field.

2) while working on data science project, i have face some problem at data cleaning and over come the overfitting problem 

3) firstly i analyze sales by customer and also i notice which time it goes high and now i will see top-selling and underperforming and i will predict demand    using time series model.

4) i will pick food app and i will do recommendations on person to person which will increases sales based on customer needs.

5) loan eligibility, it was a classification project. collect data, data understanding, data cleaning, feature engineering & feature selection, splitting data, modelling, evaluation, model selection.

6) by doing feature selection, we can reduce the feature and also it decreases the processing time and improve model performance by reducing the over fitting problem by removing unimportant features.

7) in logistic regression, if two predictors are highly correlated means it was a multi collinearity problem.

8) confidence interval means a true value lies between a range.

9) in k-means we select the k value by using elbow method

10) anomaly or outlier, we can identify by using boxplot or by using IQR also.

11) i will go through by checking missing values and duplicates or any wrong data entire and check the skewness by using histplot.

12) by time series model we can find patterns and trends on data, i have worked on sales analysis there i see the how sales was increases in a year and which month the sales was getting more and which month the sales was decreases and which area the sales was more and some areas have very less sales also we can do promotion to increases the sales.

13) gradient descent means it will reduce the error slowly.

14) log-loss means we can see how much the predicted values are true, roc-auc means it will tells how much your model performance.

15) multi collinearity means the input features was have more correlation to each other, to handle it drop a feature which have multi collinearity problem or we can apply pca or L1 or L2 regularization, they can handle multi collinearity problem.

16) VIF means variance inflation factor it will detect the multi collinearity if VIF is greater than 4 means, it will indicate the collinearity 

17) to predict credit card fraud, collect transaction data, data understanding, data cleaning, feature engineering & feature selection, splitting data, modelling, evaluation, model selection.

18) overfitting means the train accuracy is more and the test accuracy is less it indicates overfitting problem, to reduce overfitting problem we can remove outliers and check the skewness and remove unimportant features to reduce overfitting problem.

19) p-value means observing result if null hypothesis is true, checking whether we accept or reject the value. if p-value is less than 0.05 means we can reject it.

20) to predict credit risk, we want features like no.of dependences and self employee and repayment history and spending history and credit score and transaction patterns and so on, by using this important features we can predict it.







